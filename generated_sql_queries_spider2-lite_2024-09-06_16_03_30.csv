db_id|question|generated_sql_query|gold_sql_query
bigquery-public-data.ga4_obfuscated_sample_ecommerce|How many pseudo users were active in the last 7 days but inactive in the last 2 days as of January 7, 2021?|select count(distinct user_pseudo_id) from `bigquery-public-data`.ga4_obfuscated_sample_ecommerce.events_20210101 as t1 inner join `bigquery-public-data`.ga4_obfuscated_sample_ecommerce.events_20210102 as t2 on t1.user_pseudo_id = t2.user_pseudo_id inner join `bigquery-public-data`.ga4_obfuscated_sample_ecommerce.events_20210103 as t3 on t1.user_pseudo_id = t3.user_pseudo_id inner join `bigquery-public-data`.ga4_obfuscated_sample_ecommerce.events_20210104 as t4 on t1.user_pseudo_id = t4.user_pseudo_id inner join `bigquery-public-data`.ga4_obfuscated_sample_ecommerce.events_20210105 as t5 on t1.user_pseudo_id = t5.user_pseudo_id inner join `bigquery-public-data`.ga4_obfuscated_sample_ecommerce.events_20210106 as t6 on t1.user_pseudo_id = t6.user_pseudo_id inner join `bigquery-public-data`.ga4_obfuscated_sample_ecommerce.events_20210107 as t7 on t1.user_pseudo_id = t7.user_pseudo_id where not t1.user_pseudo_id in ( select user_pseudo_id from `bigquery-public-data`.ga4_obfuscated_sample_ecommerce.events_20210105 union distinct select user_pseudo_id from `bigquery-public-data`.ga4_obfuscated_sample_ecommerce.events_20210106 )|select count(distinct mdaysusers.user_pseudo_id) as n_day_inactive_users_count from ( select user_pseudo_id from `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` as t cross join unnest(t.event_params) as event_params where event_params.key = 'engagement_time_msec' and event_params.value.int_value > 0 /* has engaged in last m = 7 days */ and event_timestamp > unix_micros(timestamp_sub(timestamp('2021-01-07 23:59:59'), interval 7 day)) /* include only relevant tables based on the fixed timestamp */ and _table_suffix between '20210101' and '20210107' ) as mdaysusers left join ( select user_pseudo_id from `bigquery-public-data.ga4_obfuscated_sample_ecommerce.events_*` as t cross join unnest(t.event_params) as event_params where event_params.key = 'engagement_time_msec' and event_params.value.int_value > 0 /* has engaged in last n = 2 days */ and event_timestamp > unix_micros(timestamp_sub(timestamp('2021-01-07 23:59:59'), interval 2 day)) /* include only relevant tables based on the fixed timestamp */ and _table_suffix between '20210105' and '20210107' ) as ndaysusers on mdaysusers.user_pseudo_id = ndaysusers.user_pseudo_id where ndaysusers.user_pseudo_id is null;
bigquery-public-data.google_analytics_sample|Find the top-selling product among customers who bought 'Youtube Men’s Vintage Henley' in July 2017, excluding itself.|with productpurchases as ( select s.fullvisitorid, h.product.productsku, h.product.v2productname, h.product.v2productcategory, h.product.productquantity from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170701 as s inner join s.hits as h where s.date >= '20170701' and s.date <= '20170731' ), filteredpurchases as ( select fullvisitorid, productsku, v2productname, v2productcategory, productquantity from productpurchases where v2productname = 'youtube men’s vintage henley' ), topsellingproducts as ( select fullvisitorid, productsku, v2productname, v2productcategory, sum(productquantity) as totalquantity from productpurchases where fullvisitorid in ( select fullvisitorid from filteredpurchases ) and productsku <> 'youtube men’s vintage henley' group by fullvisitorid, productsku, v2productname, v2productcategory ) select v2productname, v2productcategory, sum(totalquantity) as totalquantity from topsellingproducts group by v2productname, v2productcategory order by sum(totalquantity) desc limit 1;|"with get_cus_id as ( select distinct fullvisitorid as henley_customer_id from `bigquery-public-data.google_analytics_sample.ga_sessions_201707*`, unnest(hits) as hits, unnest(hits.product) as product where product.v2productname = ""youtube men's vintage henley"" and product.productrevenue is not null ) select product.v2productname as other_purchased_products from `bigquery-public-data.google_analytics_sample.ga_sessions_201707*` tab_a right join get_cus_id on get_cus_id.henley_customer_id=tab_a.fullvisitorid, unnest(hits) as hits, unnest(hits.product) as product where tab_a.fullvisitorid in ( select * from get_cus_id ) and product.v2productname <> ""youtube men's vintage henley"" and product.productrevenue is not null group by product.v2productname order by sum(product.productquantity) desc limit 1;"
bigquery-public-data.google_analytics_sample|Which traffic source receives the top revenue in 2017 and what is the difference (millions, rounded to two decimal places) between its highest and lowest revenue months?|with monthlyrevenue as ( select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170101 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170102 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170103 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170104 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170105 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170106 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170107 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170108 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170109 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170110 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170111 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170112 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170113 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170114 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170115 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170116 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170117 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170118 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170119 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170120 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170121 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170122 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170123 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170124 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170125 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170126 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170127 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170128 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170129 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170130 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170131 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170201 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170202 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170203 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170204 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170205 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170206 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170207 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170208 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170209 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170210 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170211 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170212 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170213 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170214 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170215 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170216 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170217 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170218 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170219 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170220 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170221 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170222 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170223 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170224 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170225 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170226 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170227 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170228 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170301 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170302 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170303 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170304 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170305 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170306 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170307 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170308 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170309 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170310 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170311 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170312 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170313 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170314 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170315 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170316 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170317 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170318 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170319 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170320 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170321 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170322 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170323 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170324 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170325 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170326 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170327 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170328 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170329 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170330 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170331 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170401 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170402 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170403 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170404 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170405 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170406 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum(t.totals.totaltransactionrevenue) as revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170407 as t union all select t.trafficsource.source as traffic_source, date_trunc(t.date, month) as revenue_month, sum|"with monthly_revenue as ( select format_date(""%y%m"", parse_date(""%y%m%d"", date)) as month, trafficsource.source as source, round(sum(totals.totaltransactionrevenue) / 1000000, 2) as revenue from `bigquery-public-data.google_analytics_sample.ga_sessions_2017*` group by 1, 2 ), yearly_revenue as ( select source, sum(revenue) as total_revenue from monthly_revenue group by source ), top_source as ( select source from yearly_revenue order by total_revenue desc limit 1 ), source_monthly_revenue as ( select month, source, revenue from monthly_revenue where source in (select source from top_source) ), revenue_diff as ( select source, round(max(revenue), 2) as max_revenue, round(min(revenue), 2) as min_revenue, round(max(revenue) - min(revenue), 2) as diff_revenue from source_monthly_revenue group by source ) select source, diff_revenue from revenue_diff;"
bigquery-public-data.google_analytics_sample|I wonder how many days between the first transaction and the first visit for each transacting visitor in Feburary 2017, along with the device used in the transaction.|with firsttransactions as ( select visitorid, min(visitstarttime) as first_transaction_start_time from `bigquery-public-data`.google_analytics_sample.ga_sessions_201702* where totals.transactions > 0 group by 1 ), firstvisits as ( select visitorid, min(visitstarttime) as first_visit_start_time from `bigquery-public-data`.google_analytics_sample.ga_sessions_201702* group by 1 ) select ft.visitorid, timestamp_diff(ft.first_transaction_start_time, fv.first_visit_start_time, day) as days_between, t.device.browser as transaction_device from firsttransactions ft inner join firstvisits fv on ft.visitorid = fv.visitorid inner join `bigquery-public-data`.google_analytics_sample.ga_sessions_201702* as t on ft.visitorid = t.visitorid where ft.first_transaction_start_time = t.visitstarttime group by 1, 2, 3 order by days_between;|declare start_date string default '20170201'; declare end_date string default '20170228'; with visit as ( select fullvisitorid, min(date) as date_first_visit from `bigquery-public-data.google_analytics_sample.ga_sessions_*` where _table_suffix between start_date and end_date group by fullvisitorid ), transactions as ( select fullvisitorid, min(date) as date_transactions from `bigquery-public-data.google_analytics_sample.ga_sessions_*` as ga, unnest(ga.hits) as hits where hits.transaction.transactionid is not null and _table_suffix between start_date and end_date group by fullvisitorid ), device_transactions as ( select distinct fullvisitorid, date, device.devicecategory from `bigquery-public-data.google_analytics_sample.ga_sessions_*` as ga, unnest(ga.hits) as hits where hits.transaction.transactionid is not null and _table_suffix between start_date and end_date ), visits_transactions as ( select visit.fullvisitorid, date_first_visit, date_transactions, device_transactions.devicecategory as device_transaction from visit join transactions on visit.fullvisitorid = transactions.fullvisitorid join device_transactions on visit.fullvisitorid = device_transactions.fullvisitorid and transactions.date_transactions = device_transactions.date ) select fullvisitorid, date_diff(parse_date('%y%m%d', date_transactions), parse_date('%y%m%d', date_first_visit), day) as time, device_transaction from visits_transactions order by fullvisitorid;
bigquery-public-data.google_analytics_sample|What's the maximum monthly, weekly, and daily product revenues (in millions) generated by the top-performing traffic source in the first half of 2017?|with monthlyrevenue as ( select date_trunc(date, month) as month, trafficsource.source as traffic_source, sum(hits.product.productrevenue) as monthly_product_revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170101, unnest(hits) as hits where cast(date as date) between '2017-01-01' and '2017-06-30' group by 1, 2 ), weeklyrevenue as ( select date_trunc(date, week) as week, trafficsource.source as traffic_source, sum(hits.product.productrevenue) as weekly_product_revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170101, unnest(hits) as hits where cast(date as date) between '2017-01-01' and '2017-06-30' group by 1, 2 ), dailyrevenue as ( select cast(date as date) as day, trafficsource.source as traffic_source, sum(hits.product.productrevenue) as daily_product_revenue from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170101, unnest(hits) as hits where cast(date as date) between '2017-01-01' and '2017-06-30' group by 1, 2 ), toptrafficsource as ( select traffic_source from ( select traffic_source, sum(monthly_product_revenue) as total_revenue from monthlyrevenue group by 1 order by total_revenue desc limit 1 ) ) select max(monthly_product_revenue) / 1000000 as max_monthly_product_revenue, max(weekly_product_revenue) / 1000000 as max_weekly_product_revenue, max(daily_product_revenue) / 1000000 as max_daily_product_revenue from monthlyrevenue inner join weeklyrevenue on monthlyrevenue.month = weeklyrevenue.week inner join dailyrevenue on monthlyrevenue.month = dailyrevenue.day inner join toptrafficsource on monthlyrevenue.traffic_source = toptrafficsource.traffic_source; **explanation:** 1. **monthlyrevenue, weeklyrevenue, dailyrevenue ctes:** - calculate the sum of product revenues for each month, week, and day, grouping by the respective time unit and the traffic source. - this step aggregates the product revenues across all sessions within each time period for each traffic source. 2. **toptrafficsource cte:** - find the traffic source with the highest total product revenue across all months in the first half of 2017. - we achieve this by: - selecting the `traffic_source` and summing `monthly_product_revenue` grouped by traffic source. - ordering the result in descending order of `total_revenue`. - taking the top 1 result using `limit 1`. 3. **final select statement:** - use the ctes to find the maximum monthly, weekly, and daily product revenues generated by the top-performing traffic source. - the `inner join` conditions ensure we are looking at the same traffic source across all time periods. - divide the revenues by 1,000,000 to express them in millions. this query effectively determines the peak product revenues generated by the most successful traffic source in the specified time frame.|declare start_date string default '20170101'; declare end_date string default '20170630'; -- step 1: calculate daily, weekly, and monthly revenues for each traffic source with daily_revenue as ( select trafficsource.source as source, date, sum(productrevenue) / 1000000 as revenue from `bigquery-public-data.google_analytics_sample.ga_sessions_*`, unnest (hits) as hits, unnest (hits.product) as product where _table_suffix between start_date and end_date group by source, date ), weekly_revenue as ( select source, concat(extract(year from (parse_date('%y%m%d', date))), 'w', extract(week from (parse_date('%y%m%d', date)))) as week, sum(revenue) as revenue from daily_revenue group by source, week ), monthly_revenue as ( select source, concat(extract(year from (parse_date('%y%m%d', date))),'0', extract(month from (parse_date('%y%m%d', date)))) as month, sum(revenue) as revenue from daily_revenue group by source, month ), -- step 2: determine the top-performing traffic source top_source as ( select source, sum(revenue) as total_revenue from daily_revenue group by source order by total_revenue desc limit 1 ), -- step 3: calculate maximum revenues for the top-performing traffic source max_revenues as ( ( select 'daily' as time_type, date as time, source, max(revenue) as max_revenue from daily_revenue where source = (select source from top_source) group by source, date order by max_revenue desc limit 1 ) union all ( select 'weekly' as time_type, week as time, source, max(revenue) as max_revenue from weekly_revenue where source = (select source from top_source) group by source, week order by max_revenue desc limit 1 ) union all ( select 'monthly' as time_type, month as time, source, max(revenue) as max_revenue from monthly_revenue where source = (select source from top_source) group by source, month order by max_revenue desc limit 1 ) ) -- step 4: select final results select time_type, time, source, max_revenue from max_revenues order by time_type, time;
bigquery-public-data.google_analytics_sample|Compare the average pageviews per visitor between purchase and non-purchase sessions for each month from April to July in 2017.|with monthlysessions as ( select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170401 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170402 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170403 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170404 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170405 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170406 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170407 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170408 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170410 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170411 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170412 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170413 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170414 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170415 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170416 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170417 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170418 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170419 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170420 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170421 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170422 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170423 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170424 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170425 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170426 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170427 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170428 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170429 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170430 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170501 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170502 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170503 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170504 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170505 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170506 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170507 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170508 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170509 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170510 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170511 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170512 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170513 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170514 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170515 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170516 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170517 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170518 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170519 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170520 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170521 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170522 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170523 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170524 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170525 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170526 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170527 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170528 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170529 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170530 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170531 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170601 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170602 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170603 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170604 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170605 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170606 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170607 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170608 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170609 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170610 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170611 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170612 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170613 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170614 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170615 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170616 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170617 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170618 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170619 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170620 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170621 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170622 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170623 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170624 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170625 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170626 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170627 union all select date(visitstarttime) as session_date, case when totals.transactions > 0 then 'purchase' else 'non-purchase' end as session_type, totals.pageviews, visitorid from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170628 union all|with cte1 as ( select concat(extract(year from (parse_date('%y%m%d', date))), '0', extract(month from (parse_date('%y%m%d', date)))) as month, sum(totals.pageviews) / count(distinct fullvisitorid) as avg_pageviews_non_purchase from `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`, unnest (hits) as hits, unnest (hits.product) as product where _table_suffix between '0401' and '0731' and totals.transactions is null and product.productrevenue is null group by month ), cte2 as ( select concat(extract(year from (parse_date('%y%m%d', date))), '0', extract(month from (parse_date('%y%m%d', date)))) as month, sum(totals.pageviews) / count(distinct fullvisitorid) as avg_pageviews_purchase from `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`, unnest (hits) as hits, unnest (hits.product) as product where _table_suffix between '0401' and '0731' and totals.transactions >= 1 and product.productrevenue is not null group by month ) select month, avg_pageviews_purchase, avg_pageviews_non_purchase from cte1 inner join cte2 using(month) order by month;
bigquery-public-data.google_analytics_sample|What's the most popular other purchased product in July 2017 with consumers who bought products relevant to YouTube?|"with sessions_with_youtube_purchases as ( select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170701 where hits.page.pagepath like '%youtube%' -- assuming ""youtube"" is a string present in the page path of youtube-related products and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170702 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170703 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170704 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170705 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170706 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170707 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170708 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170709 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170710 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170711 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170712 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170713 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170714 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170715 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170716 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170717 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170718 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170719 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170720 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170721 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170722 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170723 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170724 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170725 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170726 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170727 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170728 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170729 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170730 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null union all select fullvisitorid, visitid, hits.product.productsku from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170731 where hits.page.pagepath like '%youtube%' and hits.product.productsku is not null ), sessions_with_multiple_purchases as ( select fullvisitorid, visitid, productsku from sessions_with_youtube_purchases where fullvisitorid in ( select distinct fullvisitorid from sessions_with_youtube_purchases group by 1 having count(distinct productsku) > 1 ) ), popular_other_products as ( select productsku, count(distinct fullvisitorid) as distinct_visitors from sessions_with_multiple_purchases group by 1 ) select productsku from popular_other_products order by distinct_visitors desc limit 1;"|with product_and_quatity as ( select distinct v2productname as other_purchased_products, sum(productquantity) as quatity from `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`, unnest(hits) as hits, unnest(hits.product) as product where _table_suffix between '0701' and '0731' and product.productrevenue is not null and v2productname not like '%youtube%' and fullvisitorid in ( select distinct fullvisitorid from `bigquery-public-data.google_analytics_sample.ga_sessions_2017*`, unnest(hits) as hits, unnest(hits.product) as product where _table_suffix between '0701' and '0731' and product.productrevenue is not null and v2productname like '%youtube%' ) group by v2productname ) select other_purchased_products from product_and_quatity order by quatity desc limit 1;
bigquery-public-data.google_analytics_sample|"What's the most common next page for visitors who were part of ""Data Share"" campaign and after they accessed the page starting with '/home' in January 2017. And what's the maximum duration time (in seconds) when they visit the corresponding home page?"|with campaignsessions as ( select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170101 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170102 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170103 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170104 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170105 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170106 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170107 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170108 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170109 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170110 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170111 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170112 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170113 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170114 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170115 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170116 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170117 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170118 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170119 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170120 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170121 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170122 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170123 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170124 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170125 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170126 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170127 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170128 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170129 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170130 as s where s.trafficsource.campaign = 'data share' union all select s.visitid, s.visitstarttime, s.fullvisitorid, s.trafficsource.campaign as campaign from `bigquery-public-data`.google_analytics_sample.ga_sessions_20170131 as s where s.trafficsource.campaign = 'data share' ), homepagevisits as ( select cs.visitid, cs.visitstarttime, h.hitnumber, h.time, h.page.pagepath from campaignsessions as cs inner join cs.hits as h on h.page.pagepath like '/home%' ), nextpagevisits as ( select hpv.visitid, hpv.visitstarttime, hpv.hitnumber, hpv.time, hpv.pagepath as homepage, h.hitnumber as nexthitnumber, h.time as nexttime, h.page.pagepath as nextpagepath from homepagevisits as hpv inner join hpv.hits as h on h.hitnumber > hpv.hitnumber where h.page.pagepath != hpv.pagepath ) select nextpagepath, max(nexttime - hpv.time) as max_duration_time_seconds, count(*) as page_count from nextpagevisits as npv inner join homepagevisits as hpv on npv.visitid = hpv.visitid and npv.visitstarttime = hpv.visitstarttime group by nextpagepath order by page_count desc limit 1 ;|with page_visit_sequence as ( select fullvisitorid, visitid, pagepath, lead(timestamp, 1) over (partition by fullvisitorid, visitid order by timestamp) - timestamp as page_duration, lead(pagepath, 1) over (partition by fullvisitorid, visitid order by timestamp) as next_page, rank() over (partition by fullvisitorid, visitid order by timestamp) as step_number from ( select pages.fullvisitorid, pages.visitid, pages.pagepath, visitors.campaign, min(pages.timestamp) timestamp from ( select fullvisitorid, visitid, trafficsource.campaign campaign from `bigquery-public-data.google_analytics_sample.ga_sessions_*`, unnest(hits) as hits where _table_suffix between '20170101' and '20170131' and hits.type='page' and regexp_contains(hits.page.pagepath, r'^/home') and regexp_contains(trafficsource.campaign, r'data share') ) as visitors join( select fullvisitorid, visitid, visitstarttime + hits.time / 1000 as timestamp, hits.page.pagepath as pagepath from `bigquery-public-data.google_analytics_sample.ga_sessions_*`, unnest(hits) as hits where _table_suffix between '20170101' and '20170131' ) as pages on visitors.fullvisitorid = pages.fullvisitorid and visitors.visitid = pages.visitid group by pages.fullvisitorid, visitors.campaign, pages.visitid, pages.pagepath order by pages.fullvisitorid, pages.visitid, timestamp ) order by fullvisitorid, visitid, step_number ), most_common_next_page as ( select next_page, count(next_page) as page_count from page_visit_sequence where next_page is not null and regexp_contains(pagepath, r'^/home') group by next_page order by page_count desc limit 1 ), max_page_duration as ( select max(page_duration) as max_duration from page_visit_sequence where page_duration is not null and regexp_contains(pagepath, r'^/home') ) select next_page, max_duration from most_common_next_page, max_page_duration;
patents-public-data.patents|Get the number of patent publications and the average number of inventors per patent in the US every five years from 1945 to 2020?|with publicationcounts as ( select cast(publication_date / 10000 as int64) as year, count(*) as publication_count from `patents-public-data.patents.publications` where country_code = 'us' and publication_date >= 19450000 and publication_date < 20210000 group by year ), inventorcounts as ( select cast(publication_date / 10000 as int64) as year, count(inventor) as inventor_count from `patents-public-data.patents.publications` where country_code = 'us' and publication_date >= 19450000 and publication_date < 20210000 group by year ) select p.year, publication_count, cast(i.inventor_count as bignumeric) / cast(publication_count as bignumeric) as avg_inventors_per_patent from publicationcounts as p join inventorcounts as i on p.year = i.year where mod(p.year, 5) = 0 order by p.year;|select avg(num_inventors) as avg_inventors, count(*) as cnt, filing_year from ( select any_value(array_length(inventor)) as num_inventors, any_value(country_code) as country_code, any_value(cast(floor(filing_date / (5 * 10000)) as int64)) * 5 as filing_year from `patents-public-data.patents.publications` as pubs where filing_date > 19450000 and filing_date < 20200000 and array_length(inventor) > 0 group by publication_number ) where country_code in ('us') group by filing_year, country_code order by filing_year;
patents-public-data.patents|For the assignee who has been the most active in the patent category 'A61K39', I'd like to know the five patent jurisdictions code where they filed the most patents during their busiest year, separated by commas.|with assigneeactivity as ( select p.assignee_harmonized.name as assignee_name, p.country_code as jurisdiction, p.application_kind as patent_kind, p.filing_date as filing_year, count(*) as patent_count from `patents-public-data.patents.publications` as p where p.application_kind = 'a' group by 1, 2, 3, 4 ), rankedactivity as ( select assignee_name, jurisdiction, filing_year, patent_count, row_number() over (partition by assignee_name order by patent_count desc) as rank_within_assignee from assigneeactivity ), assigneetopyear as ( select assignee_name, filing_year as busiest_year from rankedactivity where rank_within_assignee = 1 ), topjurisdictions as ( select assignee_name, jurisdiction, patent_count, row_number() over (partition by assignee_name order by patent_count desc) as rank_within_assignee_jurisdiction from rankedactivity where filing_year = ( select busiest_year from assigneetopyear where assigneetopyear.assignee_name = rankedactivity.assignee_name ) ), topassignee as ( select assignee_name, jurisdiction, patent_count, busiest_year from topjurisdictions where rank_within_assignee_jurisdiction <= 5 ) select ta.assignee_name, group_concat(distinct ta.jurisdiction order by ta.patent_count desc) as top_jurisdictions from topassignee as ta left join `patents-public-data.patents.publications` as p on ta.assignee_name = p.assignee_harmonized.name left join p.cpc as cpc on true where cpc.code = 'a61k39' group by 1 order by ta.patent_count desc limit 1;|"with patentapplications as ( select any_value(assignee_harmonized) as assignee_harmonized, -- collects any sample of harmonized assignee data. any_value(filing_date) as filing_date, -- collects any sample of filing date. any_value(country_code) as country_code, -- collects any sample of country code. application_number -- the unique identifier for each patent application. from `patents-public-data.patents.publications` as pubs -- using the patents publications dataset. where exists ( -- checks if there exists a cpc code ""a61k39"" within the nested cpc field. select 1 from unnest(pubs.cpc) as c where regexp_contains(c.code, ""a61k39"") ) group by application_number -- group by application number to ensure distinct entries. ) ,assigneeapplications as ( select count(*) as year_country_cnt, -- count of applications per assignee, year, and country. a.name as assignee_name, -- name of the assignee. cast(floor(filing_date / 10000) as int64) as filing_year, -- extracts the year from the filing date. apps.country_code -- country code of the application. from patentapplications as apps -- using the previously defined cte. cross join unnest(assignee_harmonized) as a -- expanding the assignee_harmonized array. group by a.name, filing_year, country_code -- grouping by assignee, year, and country. ) -- cte to aggregate data by assignee and year and to collect top 5 countries by application count. ,aggregateddata as ( select sum(year_country_cnt) as year_cnt, -- sum of all applications per assignee per year. assignee_name, filing_year, -- aggregates the top 5 countries by their application counts in descending order. string_agg(country_code order by year_country_cnt desc limit 5) as countries from assigneeapplications -- using the assigneeapplications cte. group by assignee_name, filing_year -- grouping results by assignee and year. ) -- final aggregation to find the year with the highest application count for each assignee. ,finalaggregation as ( select sum(year_cnt) as total_count, -- total count of applications for each assignee. assignee_name, -- aggregates into a structure the year and countries data with the highest application count. array_agg( struct<cnt int64, filing_year int64, countries string> (year_cnt, filing_year, countries) order by year_cnt desc limit 1 )[safe_ordinal(1)] as largest_year -- selects the year with the highest application count. from aggregateddata -- using the aggregateddata cte. group by assignee_name -- grouping by assignee. ), final_data as ( select total_count, assignee_name, largest_year from finalaggregation -- using the finalaggregation cte. order by total_count desc ) select largest_year.countries from final_data limit 1"
patents-public-data.patents|In which year did the assignee with the most applications in the patent category 'A61K39' file the most?|with assigneeapplications as ( select p.assignee_harmonized, count(distinct p.publication_number) as application_count, max(p.filing_date) as max_filing_date from `patents-public-data.patents.publications_202212` as p where p.application_kind = 'a' and p.ipc.code like 'a61k39%' group by p.assignee_harmonized ), rankedassigneeapplications as ( select assignee_harmonized, application_count, max_filing_date, rank() over (order by application_count desc) as rank from assigneeapplications ) select cast(max_filing_date / 10000 as string) as year from rankedassigneeapplications where rank = 1;|"with patentapplications as ( select any_value(assignee_harmonized) as assignee_harmonized, -- randomly sampling assignee data any_value(filing_date) as filing_date, -- randomly sampling filing date application_number -- the unique identifier for each patent application from `patents-public-data.patents.publications` as pubs -- using the patent publications dataset where exists ( -- checks if there is a cpc code ""a61k39"" select 1 from unnest(pubs.cpc) as c where regexp_contains(c.code, ""a61k39"") ) group by application_number -- grouping by application number to ensure unique entries ) , assigneeapplications as ( select count(*) as total_applications, -- calculating the total number of applications a.name as assignee_name, -- name of the assignee cast(floor(filing_date / 10000) as int64) as filing_year -- extracting the year from the filing date from patentapplications cross join unnest(assignee_harmonized) as a -- expanding the assignee_harmonized array group by a.name, filing_year -- grouping by assignee and year ) , totalapplicationsperassignee as ( select assignee_name, sum(total_applications) as total_applications -- sum of all applications per assignee from assigneeapplications group by assignee_name order by total_applications desc limit 1 -- selecting only the assignee with the highest total applications ) , maxyearfortopassignee as ( select aa.assignee_name, aa.filing_year, aa.total_applications from assigneeapplications aa inner join totalapplicationsperassignee tapa on aa.assignee_name = tapa.assignee_name order by aa.total_applications desc limit 1 -- finding the year with the most applications for the top assignee ) select filing_year from maxyearfortopassignee"
patents-public-data.patents|For patent class A01B3, I want to analyze the information of the top 20 assignees based on the total number of applications. Please provide the following five pieces of information: the names of these assignees, their total number of applications, the year with the most applications, the number of applications in that year, and the country code with the most applications during that year.|with assigneecounts as ( select assignee_harmonized.name as assignee_name, count(*) as total_applications, extract(year from timestamp_seconds(publication_date)) as publication_year from `patents-public-data.patents.publications_202212` where cpc.code like 'a01b%3' group by 1, 2 ), rankedassignees as ( select assignee_name, total_applications, publication_year, row_number() over (partition by assignee_name order by total_applications desc) as rank from assigneecounts ), topassignees as ( select assignee_name, total_applications, publication_year, max(total_applications) over (partition by assignee_name) as max_applications, row_number() over (partition by assignee_name order by total_applications desc) as rank_within_assignee from rankedassignees where rank = 1 ) select assignee_name, total_applications, publication_year as year_with_most_applications, max_applications, ( select country_code from `patents-public-data.patents.publications_202212` where assignee_harmonized.name = assignee_name and extract(year from timestamp_seconds(publication_date)) = publication_year group by 1 order by count(*) desc limit 1 ) as country_code_with_most_applications_in_that_year from topassignees where rank_within_assignee = 1 order by total_applications desc limit 20;|"with patentapplications as ( select any_value(assignee_harmonized) as assignee_harmonized, -- collects any sample of harmonized assignee data. any_value(filing_date) as filing_date, -- collects any sample of filing date. any_value(country_code) as country_code, -- collects any sample of country code. application_number -- the unique identifier for each patent application. from `patents-public-data.patents.publications` as pubs -- using the patents publications dataset. where exists ( select 1 from unnest(pubs.cpc) as c where regexp_contains(c.code, ""a01b3"") ) group by application_number -- group by application number to ensure distinct entries. ) ,assigneeapplications as ( select count(*) as year_country_cnt, -- count of applications per assignee, year, and country. a.name as assignee_name, -- name of the assignee. cast(floor(filing_date / 10000) as int64) as filing_year, -- extracts the year from the filing date. apps.country_code -- country code of the application. from patentapplications as apps -- using the previously defined cte. cross join unnest(assignee_harmonized) as a -- expanding the assignee_harmonized array. group by a.name, filing_year, country_code -- grouping by assignee, year, and country. ) -- cte to aggregate data by assignee and year and to collect top 5 countries by application count. ,aggregateddata as ( select sum(year_country_cnt) as year_cnt, -- sum of all applications per assignee per year. assignee_name, filing_year, -- aggregates the top 5 countries by their application counts in descending order. string_agg(country_code order by year_country_cnt desc limit 1) as countries from assigneeapplications -- using the assigneeapplications cte. group by assignee_name, filing_year -- grouping results by assignee and year. ) -- final aggregation to find the year with the highest application count for each assignee. ,finalaggregation as ( select sum(year_cnt) as total_count, -- total count of applications for each assignee. assignee_name, -- aggregates into a structure the year and countries data with the highest application count. array_agg( struct<cnt int64, filing_year int64, countries string> (year_cnt, filing_year, countries) order by year_cnt desc limit 1 )[safe_ordinal(1)] as largest_year -- selects the year with the highest application count. from aggregateddata -- using the aggregateddata cte. group by assignee_name -- grouping by assignee. ) -- selecting final results including total application count, assignee name, and details of their largest year. select total_count, assignee_name, largest_year.cnt, largest_year.filing_year, largest_year.countries from finalaggregation -- using the finalaggregation cte. order by total_count desc -- ordering by total application count in descending order. limit 20; -- limits the results to the top 20 assignees."
patents-public-data.patents|How many US patent applications about IoT applications were filed each month from 2008 to 2022?|with monthlyapplications as ( select generate_timestamp_array( timestamp('2008-01-01'), timestamp('2022-12-31'), interval 1 month ) as filingmonth, cast(strftime('%y-%m', filingmonth) as string) as filingyearmonth from unnest([1]) as dummy ), filteredpublications as ( select p.filing_date, p.country_code, p.application_kind, p.application_number_formatted, p.publication_number from `patents-public-data.patents.publications` as p where p.application_kind = 'a' union all select p.filing_date, p.country_code, p.application_kind, p.application_number_formatted, p.publication_number from `patents-public-data.patents.publications_202105` as p where p.application_kind = 'a' union all select p.filing_date, p.country_code, p.application_kind, p.application_number_formatted, p.publication_number from `patents-public-data.patents.publications_202212` as p where p.application_kind = 'a' ) select ma.filingyearmonth, count(distinct fp.application_number_formatted) as applicationcount from monthlyapplications as ma left outer join filteredpublications as fp on cast(strftime('%y-%m', fp.filing_date) as string) = ma.filingyearmonth where fp.country_code = 'us' and fp.publication_number like '%iot%' group by 1 order by 1|with patent_matches as ( select parse_date('%y%m%d', safe_cast(any_value(patentsdb.filing_date) as string)) as patent_filing_date, patentsdb.application_number as patent_application_number, any_value(abstract_info.text) as patent_title, any_value(abstract_info.language) as patent_title_language from `patents-public-data.patents.publications` as patentsdb, unnest(abstract_localized) as abstract_info where lower(abstract_info.text) like '%internet of things%' and patentsdb.country_code = 'us' group by patent_application_number ), date_series_table as ( select day, 0 as number_of_patents from unnest(generate_date_array( date '2008-01-01', date '2022-12-31' )) as day ) select safe_cast(format_date('%y-%m', date_series_table.day) as string) as patent_date_yearmonth, count(patent_matches.patent_application_number) as number_of_patent_applications from date_series_table left join patent_matches on date_series_table.day = patent_matches.patent_filing_date group by patent_date_yearmonth order by patent_date_yearmonth;
patents-public-data.patents|Could you find out which US utility patent granted in January 2010, with a published application, has the most forward citations over the ten years following its application date?|select p.publication_number, count(c.publication_number) as forward_citation_count from `patents-public-data.patents.publications` as p left outer join `patents-public-data.patents.publications` as c on p.publication_number = c.citation.publication_number where p.country_code = 'us' and p.application_kind = 'u' and p.kind_code = 'b2' and p.publication_date between date(2010, 1, 1) and date(2010, 1, 31) group by 1 order by forward_citation_count desc limit 1;|with patents_sample as ( -- name of our table select t1.publication_number, t1.application_number from `patents-public-data.patents.publications` t1 where country_code = 'us' -- only consider us patents and grant_date between 20100101 and 20100131 -- grant dates between 2002 and 2006 and grant_date != 0 -- only consider granted patents and publication_number like '%b2%' -- only consider patents with kind code b2 ), forward_citation as ( select distinct patents_sample.publication_number, count(distinct t3.citing_application_number) as forward_citations from patents_sample left join ( select x2.publication_number, parse_date('%y%m%d', cast(x2.filing_date as string)) as filing_date from `patents-public-data.patents.publications` x2 where x2.filing_date != 0) t2 on t2.publication_number = patents_sample.publication_number left join ( select x3.publication_number as citing_publication_number, x3.application_number as citing_application_number, parse_date('%y%m%d', cast(x3.filing_date as string)) as joined_filing_date, citation_u.publication_number as cited_publication_number from `patents-public-data.patents.publications` x3, unnest(citation) as citation_u where x3.filing_date!=0) t3 on patents_sample.publication_number = t3.cited_publication_number and t3.joined_filing_date between t2.filing_date and date_add(t2.filing_date, interval 10 year) group by patents_sample.publication_number ) select publication_number from forward_citation order by forward_citations desc limit 1
patents-public-data.patents|For US B2 patents granted in the first seven days of January 2018, tell me the publication number of each patent and the number of backward citations it has received in the SEA category.|select p.publication_number, count(c.publication_number) as backward_citations from `patents-public-data.patents.publications` as p left join `patents-public-data.patents.publications` as c on p.publication_number = c.citation.publication_number where p.country_code = 'us' and p.kind_code = 'b2' and p.publication_date between 20180101 and 20180107 and c.citation.category = 'sea' group by 1 order by backward_citations desc|with patents_sample as ( -- name of our table select t1.publication_number, t1.application_number from `patents-public-data.patents.publications` t1 where country_code = 'us' -- only consider us patents and grant_date between 20180101 and 20180107 -- grant dates between 2002 and 2006 and grant_date != 0 -- only consider granted patents and publication_number like '%b2%' -- only consider patents with kind code b2 ) select t1.publication_number, -- count disctinct application numbers cited by our focal patent count(distinct t3.application_number) as backward_citations from patents_sample t1 left outer join ( select -- the publication number in the joined table is the citing publication number x2.publication_number as citing_publication_number, -- the publication number in the unnested citation record is the cited publication number citation_u.publication_number as cited_publication_number, -- the category in the unnested citation record is the category of the cited publication citation_u.category as cited_publication_category from `patents-public-data.patents.publications` x2, unnest(citation) as citation_u ) t2 on t2.citing_publication_number = t1.publication_number -- citation category has to contain 'sea' and contains_substr(t2.cited_publication_category, 'sea') -- one more join to publications table to get the application number left outer join `patents-public-data.patents.publications` t3 on t2.cited_publication_number = t3.publication_number group by t1.publication_number order by t1.publication_number
patents-public-data.patents|How many US B2 patents granted between 2015 and 2018 contain claims that do not include the word 'claim'?|select count(distinct t1.publication_number) from `patents-public-data.patents.publications` as t1 inner join t1.claims_localized as t2 on true where t1.country_code = 'us' and t1.kind_code = 'b2' and t1.grant_date between 20150101 and 20181231 and t2.language = 'en' and not t2.text like '%claim%'|with patents_sample as ( select t1.publication_number, claim.text as claims_text from patents-public-data.patents.publications t1, unnest(t1.claims_localized) as claim where t1.country_code = 'us' and t1.grant_date between 20150101 and 20181231 and t1.grant_date != 0 and t1.publication_number like '%b2%' ), publication_data as ( select publication_number, countif(claims_text not like '%claim%') as nb_indep_claims from patents_sample group by publication_number ) select count(nb_indep_claims) from publication_data where nb_indep_claims != 0
patents-public-data.patents|Among the US utility B2 patents granted in January 2008, how many of them belong to families that have a total of over 300 distinct applications?|with publicationcounts as ( select family_id, count(distinct application_number) as application_count from `patents-public-data.patents.publications` where country_code = 'us' and application_kind = 'u' and kind_code = 'b2' and cast(publication_date as string)[1:4] = '2008' and cast(publication_date as string)[5:7] = '01' group by family_id ) select count(family_id) from publicationcounts where application_count > 300;|with patents_sample as ( -- name of our table select t1.publication_number, t1.application_number from patents-public-data.patents.publications t1 where country_code = 'us' -- only consider us patents and grant_date between 20080101 and 20080131 -- grant dates between 2002 and 2006 and grant_date != 0 -- only consider granted patents and publication_number like '%b2%' -- only consider patents with kind code b2 ), family_number as ( select t1.publication_number, -- count distinct application numbers sharing same family id with our focal patents count(distinct t3.application_number) as family_size, from patents_sample t1 -- join publications table to obtain family id of our focal patents left join patents-public-data.patents.publications t2 on t1.publication_number = t2.publication_number -- join publications table on family id to get all publications sharing the same family id left join patents-public-data.patents.publications t3 on t2.family_id = t3.family_id group by t1.publication_number ) select count(*) from family_number where family_size>300
patents-public-data.patents|What is the most common 4-digit IPC code among US B2 utility patents granted in the first seven days of June 2018?|select substr(t1.ipc.code, 1, 4) as ipc_code, count(*) as count from `patents-public-data.patents.publications_202105` as t1 where t1.country_code = 'us' and t1.kind_code = 'b2' and t1.application_kind = 'u' and t1.grant_date >= 20180601 and t1.grant_date <= 20180607 group by ipc_code order by count desc limit 1;|with interim_table as( select t1.publication_number, substr(ipc_u.code, 0, 4) as ipc4 from `patents-public-data.patents.publications` t1, unnest(ipc) as ipc_u where country_code = 'us' and grant_date between 20180601 and 20180607 and grant_date != 0 and publication_number like '%b2%' group by t1.publication_number, ipc4 ) select ipc4 from interim_table group by ipc4 order by count(publication_number) desc limit 1
patents-public-data.patents|For US B2 utility patents granted in April 2015, identify the most frequent 4-digit IPC code for each patent. Then, list the publication numbers and IPC4 codes of patents where this code appears 20 or more times.|with rankedipc as ( select p.publication_number, c.code, row_number() over (partition by p.publication_number order by count(*) desc) as rn from `patents-public-data.patents.publications` as p inner join p.ipc as c where p.country_code = 'us' and p.kind_code = 'b2' and p.application_kind = 'u' and p.grant_date between 20150401 and 20150430 group by 1, 2 ), frequentipc as ( select publication_number, code from rankedipc where rn = 1 ), ipccounts as ( select code, count(*) as count from frequentipc group by 1 ) select f.publication_number, f.code from frequentipc as f inner join ipccounts as ic on f.code = ic.code where ic.count >= 20 order by ic.count desc;|with interim_table as( select t1.publication_number, substr(ipc_u.code, 0, 4) as ipc4, count( substr(ipc_u.code, 0, 4) ) as ipc4_count from `patents-public-data.patents.publications` t1, unnest(ipc) as ipc_u where country_code = 'us' and grant_date between 20150401 and 20150430 and grant_date != 0 and publication_number like '%b2%' group by t1.publication_number, ipc4 ) select publication_number, ipc4 from interim_table where concat( interim_table.publication_number, interim_table.ipc4_count ) in ( select concat( publication_number, max(ipc4_count) ) from interim_table group by publication_number ) and ipc4_count >= 20
patents-public-data.patents|For the 'B2' publication granted in January 2017 in the US that received the most forward citations within a month of its filing date, determine the publication number of the most similar patent from the same filing year.|with rankedpublications as ( select p.publication_number, p.filing_date, p.grant_date, count(c.publication_number) as citation_count, row_number() over (partition by p.filing_date order by count(c.publication_number) desc) as rn from `patents-public-data.patents.publications` as p left join `patents-public-data.patents.publications` as c on p.publication_number = c.citation.publication_number where p.kind_code = 'b2' and p.country_code = 'us' and p.publication_date between date('2017-01-01') and date('2017-01-31') group by 1, 2, 3 ), similarpublications as ( select p.publication_number, p.filing_date, p.grant_date, rp.citation_count, rp.rn from `patents-public-data.patents.publications` as p left join rankedpublications as rp on p.publication_number = rp.publication_number where rp.rn = 1 and p.filing_date = rp.filing_date ) select publication_number from similarpublications where grant_date between date('2017-01-01') and date('2017-12-31') order by citation_count desc limit 1;|with patents_sample as ( select t1.publication_number, t1.application_number from `patents-public-data.patents.publications` t1 where country_code = 'us' and grant_date between 20170101 and 20170131 and publication_number like '%b2%' ), forward_citation as ( select distinct patents_sample.publication_number, count(distinct t3.citing_application_number) as forward_citations from patents_sample left join ( select x2.publication_number, parse_date('%y%m%d', cast(x2.filing_date as string)) as filing_date from `patents-public-data.patents.publications` x2 where x2.filing_date != 0 ) t2 on t2.publication_number = patents_sample.publication_number left join ( select x3.publication_number as citing_publication_number, x3.application_number as citing_application_number, parse_date('%y%m%d', cast(x3.filing_date as string)) as joined_filing_date, citation_u.publication_number as cited_publication_number from `patents-public-data.patents.publications` x3, unnest(citation) as citation_u where x3.filing_date != 0 ) t3 on patents_sample.publication_number = t3.cited_publication_number and t3.joined_filing_date between t2.filing_date and date_add(t2.filing_date, interval 1 month) group by patents_sample.publication_number ), select_sample as ( select publication_number from forward_citation order by forward_citations desc limit 1 ), t as ( select t1.publication_number, t4.publication_number as similar_publication_number, (select sum(element1 * element2) from t5.embedding_v1 element1 with offset pos join t6.embedding_v1 element2 with offset pos using (pos)) as similarity from (select * from select_sample limit 1) t1 left join ( select x3.publication_number, extract(year from parse_date('%y%m%d', cast(x3.filing_date as string))) as focal_filing_year from `patents-public-data.patents.publications` x3 where x3.filing_date != 0 ) t3 on t3.publication_number = t1.publication_number left join ( select x4.publication_number, extract(year from parse_date('%y%m%d', cast(x4.filing_date as string))) as filing_year from `patents-public-data.patents.publications` x4 where x4.filing_date != 0 ) t4 on t4.publication_number != t1.publication_number and t3.focal_filing_year = t4.filing_year left join `patents-public-data.google_patents_research.publications` t5 on t5.publication_number = t1.publication_number left join `patents-public-data.google_patents_research.publications` t6 on t6.publication_number = t4.publication_number order by t1.publication_number, similarity desc ) select t.similar_publication_number from ( select t.*, row_number() over (partition by publication_number order by similarity desc) as seqnum from t ) t where seqnum <= 1;
patents-public-data.patents|d30b2fcf-037c-4e90-9471-9d4a0a9f5e7b|select t1.publication_number, t1.application_number, t1.country_code, t1.kind_code, t1.application_kind, t1.application_number_formatted, t1.pct_number, t1.family_id, t1.spif_publication_number, t1.spif_application_number, t1.title_localized, t1.abstract_localized, t1.claims_localized, t1.claims_localized_html, t1.description_localized, t1.description_localized_html, t1.publication_date, t1.filing_date, t1.grant_date, t1.priority_date, t1.priority_claim, t1.inventor, t1.inventor_harmonized, t1.assignee, t1.assignee_harmonized, t1.examiner, t1.uspc, t1.ipc, t1.cpc, t1.fi, t1.fterm, t1.locarno, t1.citation, t1.parent, t1.child, t1.entity_status, t1.art_unit from `patents-public-data.patents.publications` as t1 inner join `patents-public-data.patents.publications_202105` as t2 on t1.publication_number = t2.publication_number inner join `patents-public-data.patents.publications_202212` as t3 on t1.publication_number = t3.publication_number where t1.publication_number like '%us%' and t1.publication_date between 20220101 and 20221231|with patents_sample as ( select publication_number, application_number from `patents-public-data.patents.publications` where publication_number = 'us-9023721-b2' ), t as ( select t1.publication_number, t4.publication_number as similar_publication_number, (select sum(element1 * element2) from t5.embedding_v1 element1 with offset pos join t6.embedding_v1 element2 with offset pos using (pos)) as similarity from (select * from patents_sample limit 1) t1 left join ( select x3.publication_number, extract(year from parse_date('%y%m%d', cast(x3.filing_date as string))) as focal_filing_year from `patents-public-data.patents.publications` x3 where x3.filing_date != 0 ) t3 on t3.publication_number = t1.publication_number left join ( select x4.publication_number, extract(year from parse_date('%y%m%d', cast(x4.filing_date as string))) as filing_year from `patents-public-data.patents.publications` x4 where x4.filing_date != 0 ) t4 on t4.publication_number != t1.publication_number and t3.focal_filing_year = t4.filing_year left join `patents-public-data.google_patents_research.publications` t5 on t5.publication_number = t1.publication_number left join `patents-public-data.google_patents_research.publications` t6 on t6.publication_number = t4.publication_number order by t1.publication_number, similarity desc ) select t.similar_publication_number, t.similarity from ( select t.*, row_number() over (partition by publication_number order by similarity desc) as seqnum from t ) t where seqnum <= 5;
patents-public-data.patents|What is the publication number of US patent granted at January 2018, with the highest originality score based on the diversity of 4-digits IPC codes from its backward citations?|with publicationcitation as ( select t1.publication_number, t1.grant_date, array_agg(t2.publication_number) as cited_publication_numbers from `patents-public-data.patents.publications_202212` as t1 inner join `patents-public-data.patents.publications_202212` as t2 on t1.publication_number in unnest(t2.citation.publication_number) where t1.country_code = 'us' and t1.application_kind = 'a' and cast(t1.grant_date as string) like '2018%' group by 1, 2 ), ipcdiversity as ( select t1.publication_number, t1.grant_date, count(distinct t2.ipc.code) as ipc_diversity_score from publicationcitation as t1 inner join `patents-public-data.patents.publications_202212` as t2 on t1.cited_publication_numbers in unnest(t2.publication_number) group by 1, 2 ) select publication_number from ipcdiversity where grant_date = '201801' order by ipc_diversity_score desc limit 1;|with patents_sample as ( -- name of our table select t1.publication_number, t1.application_number from `patents-public-data.patents.publications` t1 where country_code = 'us' -- only consider us patents and grant_date between 20180101 and 20180131 -- grant dates between 2002 and 2006 and grant_date != 0 -- only consider granted patents and publication_number like '%b2%' -- only consider patents with kind code b2 ), interim_table as ( select t1.publication_number, substr(ipc_u.code, 0, 4) as ipc4, count(substr(ipc_u.code, 0, 4)) as ipc4_count from patents-public-data.patents.publications t1, unnest(ipc) as ipc_u group by t1.publication_number, ipc4 ), chosen_ipc4_view as ( select * from interim_table where concat(interim_table.publication_number, interim_table.ipc4_count) in ( select concat(publication_number, max(ipc4_count)) from interim_table group by publication_number ) order by ipc4_count desc ), ipc_counts as ( select t1.publication_number, t3.ipc4, count(t3.ipc4) as ipc_occurrences from patents_sample t1 -- joins backward citations left join ( select x2.publication_number as citing_publication_number, citation_u.publication_number as backward_citation from patents-public-data.patents.publications x2, unnest(citation) as citation_u) t2 on t2.citing_publication_number = t1.publication_number -- joins 4-digit ipc codes of backward citations left join chosen_ipc4_view t3 on t3.publication_number = t2.backward_citation group by t1.publication_number, t3.ipc4 ), max_originality as ( select publication_number, 1 - sum(power(ipc_occurrences, 2)) / power(sum(ipc_occurrences), 2) as originality from ipc_counts group by publication_number having sum(ipc_occurrences) > 0 order by originality desc limit 1 ) select publication_number from max_originality
"patents-public-data.patents
patents-public-data.cpc"|Identify the CPC technology areas with the highest exponential moving average of patent filings each year (smoothing factor 0.2), and provide the full title and the best year for each CPC group at level 5.|-- this query cannot be executed without a schema. -- please provide the schema for your database. -- placeholder query to demonstrate the general structure -- replace placeholders with your actual table and column names with yearlypatentcounts as ( select cpc_section_5, year(filingdate) as filingyear, count(*) as patentcount from patentdata group by cpc_section_5, filingyear ), exponentialmovingaverage as ( select cpc_section_5, filingyear, patentcount, -- calculate exponential moving average (ema) -- replace 0.2 with your desired smoothing factor case when filingyear = min(filingyear) over (partition by cpc_section_5) then patentcount else (0.2 * patentcount) + (0.8 * lag(ema, 1) over (partition by cpc_section_5 order by filingyear)) end as ema from yearlypatentcounts ) select cpc_section_5, max(ema) as highestema, -- find the best year based on the highest ema filingyear as bestyear from exponentialmovingaverage group by cpc_section_5 order by highestema desc; **explanation:** 1. **yearlypatentcounts cte:** counts the number of patents filed each year for each cpc group at level 5. 2. **exponentialmovingaverage cte:** calculates the exponential moving average (ema) for each year and each cpc group. 3. **final select statement:** retrieves the cpc group, the highest ema, and the corresponding filing year (best year). **note:** * this query assumes you have a table named `patentdata` with columns `cpc_section_5` and `filingdate`. * adjust table and column names accordingly. * replace `0.2` with your desired smoothing factor for the ema calculation. * the query uses window functions `lag` and `min` to calculate the ema and determine the first filing year for each cpc group. this query provides a general framework for solving your problem. you will need to modify it based on your specific database schema and requirements.|"create temporary function highest_moving_avg(yearcnt array<struct<filing_year int64, cnt int64>>) returns struct<filing_year int64, avg int64> language js as """""" let a = 0.2; let avg = yearcnt.length > 0 ? yearcnt[0].cnt : 0; let highest = {filing_year: -1, avg: -1}; for (let x of yearcnt) { avg = a * x.cnt + (1 - a) * avg; if (avg > highest.avg) { highest = {filing_year: x.filing_year, avg: avg}; } } return highest; """"""; with patent_cpcs as ( select cd.parents, cast(floor(filing_date/10000) as int64) as filing_year from ( select any_value(cpc) as cpc, any_value(filing_date) as filing_date from `patents-public-data.patents.publications` where application_number != """" group by application_number ), unnest(cpc) as cpcs join `patents-public-data.cpc.definition` cd on cd.symbol = cpcs.code where cpcs.first = true and filing_date > 0 ) select c.titlefull, cpc_group, best_year.filing_year from ( select cpc_group, highest_moving_avg(array_agg(struct<filing_year int64, cnt int64>(filing_year, cnt) order by filing_year asc)) as best_year from ( select cpc_group, filing_year, count(*) as cnt from ( select cpc_parent as cpc_group, filing_year from patent_cpcs, unnest(parents) as cpc_parent ) group by cpc_group, filing_year order by filing_year desc, cnt desc ) group by cpc_group ) join `patents-public-data.cpc.definition` c on cpc_group = c.symbol where c.level = 5 order by c.titlefull, cpc_group asc;"
patents-public-data.patents|Find the CPC technology areas in Germany with the highest exponential moving average of patent filings each year (smoothing factor 0.1) for patents granted in December 2016. Show me the full title, CPC group and the best year for each CPC group at level 4.|with publicationcounts as ( select p.publication_number, p.filing_date, p.cpc, p.grant_date, p.country_code from `patents-public-data.patents.publications` as p ), yearlycounts as ( select publication_number, date_trunc(date(filing_date), year) as filing_year, cpc, country_code, count(*) over (partition by filing_year, cpc, country_code) as count from publicationcounts where date(grant_date) between '2016-12-01' and '2016-12-31' ), expmovingaverage as ( select filing_year, cpc, country_code, count, exp(sum(ln(count) * pow(0.1, row_number() over (partition by cpc, country_code order by filing_year))) over (partition by cpc, country_code order by filing_year)) as ema from yearlycounts ), maxema as ( select cpc, country_code, max(ema) as max_ema, filing_year as max_ema_year from expmovingaverage group by cpc, country_code ), cpctitles as ( select c.cpc.code as cpc_code, c.cpc.tree as cpc_tree, p.title_localized from `patents-public-data.patents.publications` as p inner join publicationcounts as c on p.publication_number = c.publication_number ) select c.cpc_code, c.cpc_tree, c.title_localized, m.max_ema, m.max_ema_year from maxema as m inner join cpctitles as c on m.cpc = c.cpc_code where m.country_code = 'de' and split(c.cpc_code, '/')[safe_offset(0)] like 'a%' order by c.cpc_code;|"create temporary function highest_moving_avg(yearcnt array<struct<filing_year int64, cnt int64>>) returns struct<filing_year int64, avg int64> language js as """""" let a = 0.1; let avg = yearcnt.length > 0 ? yearcnt[0].cnt : 0; let highest = {filing_year: -1, avg: -1}; for (let x of yearcnt) { avg = a * x.cnt + (1 - a) * avg; if (avg > highest.avg) { highest = {filing_year: x.filing_year, avg: avg}; } } return highest; """"""; with patent_cpcs as ( select cd.parents, cast(floor(filing_date/10000) as int64) as filing_year from ( select any_value(cpc) as cpc, any_value(filing_date) as filing_date from `patents-public-data.patents.publications` where application_number != """" and country_code = 'de' and grant_date >= 20161201 and grant_date <= 20161231 group by application_number), unnest(cpc) as cpcs join `patents-public-data.cpc.definition` cd on cd.symbol = cpcs.code where cpcs.first = true and filing_date > 0) select c.titlefull, cpc_group, best_year.filing_year from ( select cpc_group, highest_moving_avg(array_agg(struct<filing_year int64, cnt int64>(filing_year, cnt) order by filing_year asc)) as best_year from ( select cpc_group, filing_year, count(*) as cnt from ( select cpc_parent as cpc_group, filing_year from patent_cpcs, unnest(parents) as cpc_parent) group by cpc_group, filing_year order by filing_year desc, cnt desc) group by cpc_group) join `patents-public-data.cpc.definition` c on cpc_group = c.symbol where c.level = 4 order by titlefull, cpc_group asc;"
"patents-public-data.patents
patents-public-data.cpc"|Which assignee and primary CPC subclass full title most frequently cite patents assigned to 'AAAA'?|-- this query assumes the existence of tables for assignee, patent, and cpc subclass. -- please replace the table and column names with your actual schema. -- the query also assumes that the patent table includes assignee information. select assignee, cpc_subclass_full_title from ( select p.assignee, c.full_title as cpc_subclass_full_title, count(*) as citation_count from patent p join citation c on p.patent_id = c.cited_patent_id join cpc_subclass cs on c.cpc_subclass_id = cs.cpc_subclass_id where p.assignee = 'aaaa' group by p.assignee, c.full_title ) as subquery order by citation_count desc limit 1; **explanation:** 1. **subquery:** - `select p.assignee, c.full_title as cpc_subclass_full_title, count(*) as citation_count`: this selects the assignee, cpc subclass full title, and counts the number of citations. - `from patent p`: this joins the patent table with the citation table on the `patent_id` column. - `join citation c on p.patent_id = c.cited_patent_id`: this joins the citation table with the cpc subclass table on the `cpc_subclass_id` column. - `join cpc_subclass cs on c.cpc_subclass_id = cs.cpc_subclass_id`: this filters for patents assigned to 'aaaa'. - `group by p.assignee, c.full_title`: this groups the results by assignee and cpc subclass full title, counting the citations for each combination. 2. **outer query:** - `select assignee, cpc_subclass_full_title`: this selects the assignee and cpc subclass full title. - `from ( ... ) as subquery`: this retrieves the results of the subquery. - `order by citation_count desc`: this sorts the results in descending order of citation count. - `limit 1`: this retrieves only the top result, which corresponds to the most frequently cited combination. **note:** this query assumes a specific schema structure. you may need to adjust the table and column names to match your database schema.|"select citing_assignee, cpcdef.titlefull as cpc_title from ( select pubs.publication_number as citing_publication_number, cite.publication_number as cited_publication_number, citing_assignee_s.name as citing_assignee, substr(cpcs.code, 0, 4) as citing_cpc_subclass from `patents-public-data.patents.publications` as pubs, unnest(citation) as cite, unnest(assignee_harmonized) as citing_assignee_s, unnest(cpc) as cpcs where cpcs.first = true ) as pubs join ( select publication_number as cited_publication_number, cited_assignee_s.name as cited_assignee from `patents-public-data.patents.publications`, unnest(assignee_harmonized) as cited_assignee_s ) as refs on pubs.cited_publication_number = refs.cited_publication_number join `patents-public-data.cpc.definition` as cpcdef on cpcdef.symbol = citing_cpc_subclass where cited_assignee = ""aaaa"" and citing_assignee != ""aaaa"" group by citing_assignee, cpcdef.titlefull order by count(*) desc limit 1"
"patents-public-data.patents
patents-public-data.google_patents_research"|Which valid family has the most publications? Just provide their publication abstracts.|"-- this query assumes a table named ""publications"" with columns: -- - family: the family name -- - abstract: the publication abstract -- - validity: a boolean indicating if the family is valid -- -- the query returns the abstract of publications from the family with the most publications. -- in the case of a tie, it returns all the abstract of the families with the most publications. select abstract from publications where family in ( select family from publications where validity = 1 group by family order by count(*) desc limit 1 ); **explanation:** 1. **`select abstract`**: this line selects the `abstract` column from the `publications` table. 2. **`where family in (...)`**: this line filters the results to only include publications from families that satisfy the condition within the parentheses. 3. **`select family from publications where validity = 1 group by family order by count(*) desc limit 1`**: this subquery finds the family with the most publications, considering only valid families. - **`select family`**: selects the `family` column. - **`from publications`**: specifies the table to query. - **`where validity = 1`**: filters for valid families. - **`group by family`**: groups the results by family. - **`order by count(*) desc`**: orders the results by the count of publications for each family in descending order. - **`limit 1`**: limits the result to the single family with the highest count. 4. **overall**: the main query combines the results of the subquery to select the abstracts from the publications associated with the family that has the most publications. **important notes:** * this query assumes the existence of a table named ""publications"" with the specified columns. * if your actual schema differs, you'll need to adjust the column names and table names accordingly. * if there's a tie for the most publications among multiple families, this query will return all the abstracts from those families."|with family_list as ( select family_id, count(publication_number) as publication_number_count from `patents-public-data.patents.publications` group by family_id ), most_published_family as ( select family_id from family_list where family_id != '-1' order by publication_number_count desc limit 1 ), publications_with_abstracts as ( select p.family_id, gpr.abstract from `patents-public-data.google_patents_research.publications` gpr join `patents-public-data.patents.publications` p on p.publication_number = gpr.publication_number where gpr.abstract is not null and gpr.abstract != '' ), abstracts_from_top_family as ( select fwa.abstract from publications_with_abstracts fwa join most_published_family mpf on fwa.family_id = mpf.family_id ) select abstract from abstracts_from_top_family;
patents-public-data.patentsview|Can you figure out the number of forward citations within 3 years from the application date for the patent that has the most backward citations within 3 years from application among all U.S. patents?|with rankedpatents as ( select patent_id, count(distinct citation_id) as backward_citations, row_number() over (order by count(distinct citation_id) desc) as rank from `patents-public-data.patentsview.uspatentcitation` where cast(substr(date, 1, 4) as bignumeric) - cast(substr(application.date, 1, 4) as bignumeric) between 0 and 3 and patent_id in ( select patent_id from `patents-public-data.patentsview.application` where country = 'us' ) group by patent_id ), forwardcitations as ( select p.patent_id, count(distinct c.citation_id) as forward_citations from `patents-public-data.patentsview.patent` as p inner join `patents-public-data.patentsview.uspatentcitation` as c on p.id = c.citation_id inner join rankedpatents as rp on p.id = rp.patent_id where cast(substr(c.date, 1, 4) as bignumeric) - cast(substr(p.date, 1, 4) as bignumeric) between 0 and 3 and rp.rank = 1 group by p.patent_id ) select forward_citations from forwardcitations; this query works by first calculating the number of backward citations for each patent within 3 years of its application date, then ranking those patents by the number of backward citations. then, it selects the patent with the highest backward citation count (rank 1) and calculates the number of forward citations for that patent within 3 years of its application date. **explanation:** 1. **rankedpatents cte:** - selects the patent id and counts the distinct backward citations for each patent within 3 years of its application date. - filters for patents that are part of the `application` table with country 'us'. - uses `row_number()` to assign a rank based on the count of backward citations, with the highest count getting rank 1. 2. **forwardcitations cte:** - joins the `patent` table with the `uspatentcitation` table to get the forward citations for each patent. - filters for patents with rank 1 from the `rankedpatents` cte. - uses `cast` to convert the year portion of dates to bignumeric and calculates the difference between citation date and patent date to get the forward citations within 3 years. - groups the results by patent id and counts the distinct forward citations. 3. **final select statement:** - selects the `forward_citations` from the `forwardcitations` cte, providing the final result. this query gives you the number of forward citations within 3 years of the application date for the u.s. patent that has the most backward citations within 3 years of its application date.|select filterdata.fwrdcitations_3 from `patents-public-data.patentsview.application` as app, (select distinct cpc.patent_id, ifnull(citation_3.bkwdcitations_3, 0) as bkwdcitations_3, ifnull(citation_3.fwrdcitations_3, 0) as fwrdcitations_3 from `patents-public-data.patentsview.cpc_current` as cpc left join (select b.patent_id, b.bkwdcitations_3, f.fwrdcitations_3 from (select cited.patent_id, count(*) as fwrdcitations_3 from `patents-public-data.patentsview.uspatentcitation` as cited, `patents-public-data.patentsview.application` as apps where apps.country = 'us' and cited.patent_id = apps.patent_id and cited.date >= apps.date and safe_cast(cited.date as date) <= date_add(safe_cast(apps.date as date), interval 3 year) group by cited.patent_id) as f, (select cited.patent_id, count(*) as bkwdcitations_3 from `patents-public-data.patentsview.uspatentcitation` as cited, `patents-public-data.patentsview.application` as apps where apps.country = 'us' and cited.patent_id = apps.patent_id and cited.date < apps.date and safe_cast(cited.date as date) >= date_sub(safe_cast(apps.date as date), interval 3 year) group by cited.patent_id) as b where b.patent_id = f.patent_id and b.bkwdcitations_3 is not null and f.fwrdcitations_3 is not null) as citation_3 on cpc.patent_id = citation_3.patent_id ) as filterdata where app.patent_id = filterdata.patent_id order by filterdata.bkwdcitations_3 desc limit 1
patents-public-data.patentsview|I wonder which patents within CPC subsection 'C05' or group 'A01G' in the USA have at least one forward or backward citations within one month of their application dates. Give me the ids, titles, application date, forward/backward citation counts and summary texts.|with patentcitations as ( select p.id, p.title, p.date as application_date, count(distinct uspc.patent_id) as forward_citation_count, count(distinct uspc.uuid) as backward_citation_count, brf.text as summary_text from `patents-public-data.patentsview.patent` as p inner join `patents-public-data.patentsview.uspc` as uspc on p.id = uspc.patent_id left join `patents-public-data.patentsview.brf_sum_text` as brf on p.id = brf.patent_id where p.country = 'us' group by 1, 2, 3, 6 ), patentcpc as ( select pc.id, pc.title, pc.application_date, pc.forward_citation_count, pc.backward_citation_count, pc.summary_text, c.subsection_id, c.group_id from patentcitations as pc inner join `patents-public-data.patentsview.cpc` as c on pc.id = c.patent_id ) select p.id, p.title, p.application_date, p.forward_citation_count, p.backward_citation_count, p.summary_text from patentcpc as p where ( p.subsection_id = 'c05' or p.group_id = 'a01g' ) and ( p.forward_citation_count >= 1 or p.backward_citation_count >= 1 );|select app.patent_id as patent_id, patent.title, app.date as application_date, filterdata.bkwdcitations_1, filterdata.fwrdcitations_1, summary.text as summary_text from `patents-public-data.patentsview.brf_sum_text` as summary, `patents-public-data.patentsview.patent` as patent, `patents-public-data.patentsview.application` as app, ( select distinct cpc.patent_id, ifnull(citation_1.bkwdcitations_1, 0) as bkwdcitations_1, ifnull(citation_1.fwrdcitations_1, 0) as fwrdcitations_1 from `patents-public-data.patentsview.cpc_current` as cpc join ( select b.patent_id, b.bkwdcitations_1, f.fwrdcitations_1 from ( select cited.patent_id, count(*) as fwrdcitations_1 from `patents-public-data.patentsview.uspatentcitation` as cited, `patents-public-data.patentsview.application` as apps where apps.country = 'us' and cited.patent_id = apps.patent_id and cited.date >= apps.date and safe_cast(cited.date as date) <= date_add(safe_cast(apps.date as date), interval 1 month) group by cited.patent_id ) as f, ( select cited.patent_id, count(*) as bkwdcitations_1 from `patents-public-data.patentsview.uspatentcitation` as cited, `patents-public-data.patentsview.application` as apps where apps.country = 'us' and cited.patent_id = apps.patent_id and cited.date < apps.date and safe_cast(cited.date as date) >= date_sub(safe_cast(apps.date as date), interval 1 month) -- get in one year interval group by cited.patent_id ) as b where b.patent_id = f.patent_id and b.bkwdcitations_1 is not null and f.fwrdcitations_1 is not null and (b.bkwdcitations_1 > 0 or f.fwrdcitations_1 > 0) ) as citation_1 on cpc.patent_id=citation_1.patent_id where ( cpc.subsection_id = 'c05' or cpc.group_id = 'a01g' ) ) as filterdata where app.patent_id = filterdata.patent_id and summary.patent_id = app.patent_id and app.patent_id = patent.id order by application_date;
"patents-public-data.patents
patents-public-data.uspto_peds"|Can you provide the initial publication numbers for our top 100 independent patent claims with the highest word count?|"-- the provided schema is insufficient to answer the question. -- please provide the table schema with relevant columns for patent claims, word count, and publication numbers. -- for example, a table named ""patent_claims"" with columns like ""claim_id"", ""publication_number"", ""word_count"". -- assuming a table named ""patent_claims"" with relevant columns: select publication_number from patent_claims where claim_id in ( select claim_id from patent_claims order by word_count desc limit 100 ) order by publication_number; **explanation:** 1. **`select publication_number`**: this selects the publication number for each claim. 2. **`from patent_claims`**: this specifies the table containing the data. 3. **`where claim_id in ( ... )`**: this filters the results to include only claims that are in the top 100 highest word count claims. 4. **`select claim_id from patent_claims order by word_count desc limit 100`**: this subquery finds the `claim_id` of the top 100 claims with the highest word count. 5. **`order by publication_number`**: this sorts the results by publication number. **note:** this query assumes that the table `patent_claims` contains the following columns: * `claim_id`: the unique identifier for each claim. * `publication_number`: the publication number associated with the claim. * `word_count`: the word count for each claim. please replace these column names with the actual column names in your schema."|with table_a as( select pat_no, claim_no, word_ct from `patents-public-data.uspto_oce_claims.patent_claims_stats` where ind_flg='1' ), matched_publn as( select publication_number, claim_no, cast(word_ct as int64) as word_ct -- cast word_ct to int64 if it's stored as a string from table_a inner join `patents-public-data.uspto_oce_claims.match` using(pat_no) ), matched_appln as( select application_number appln_nr, publication_number publn_nr, claim_no, word_ct from matched_publn inner join( select publication_number, application_number, country_code, row_number() over(partition by application_number order by publication_date asc) row_num, kind_code, publication_date from `patents-public-data.patents.publications` ) using(publication_number) where row_num=1 ) select * from matched_appln order by word_ct desc limit 100
bigquery-public-data.github_repos|What was the average number of GitHub commits made per month in 2020 for repositories containing Python code?|with monthlycommits as ( select repo_name, extract(month from author.date) as commit_month, count(*) as commit_count from `bigquery-public-data`.github_repos.sample_commits where extract(year from author.date) = 2020 group by repo_name, commit_month ), pythonrepos as ( select distinct repo_name from `bigquery-public-data`.github_repos.languages where array_contains(language, 'python') ) select avg(commit_count) as average_commits_per_month from monthlycommits where repo_name in ( select repo_name from pythonrepos );|with cterepocommits as ( select rname as repo_name, committer.date, t1.commit, concat(cast(extract(year from timestamp_seconds(committer.time_sec)) as string), '-', lpad(cast(extract(month from timestamp_seconds(committer.time_sec)) as string), 2, '0')) as yearmonth from `bigquery-public-data.github_repos.commits` t1 left join unnest(t1.repo_name) rname where extract(year from timestamp_seconds(committer.time_sec)) = 2020 ), cterepolang as ( select t2.repo_name, l.name as langname from `bigquery-public-data.github_repos.languages` t2 left join unnest(t2.language) as l ) , monthlycommits as ( select cterepocommits.yearmonth, count(*) as commitcnts from cterepocommits inner join cterepolang on cterepocommits.repo_name = cterepolang.repo_name where cterepolang.langname = 'python' group by cterepocommits.yearmonth order by cterepocommits.yearmonth ) select avg(commitcnts) as avgmonthlycommits from monthlycommits;
bigquery-public-data.github_repos|Find out the most frequently used package in all Go source files.|select t1.package from ( select t2.package from `bigquery-public-data`.github_repos.sample_contents as t1 inner join `bigquery-public-data`.github_repos.sample_files as t2 on t1.id = t2.id where t2.path like '%.go' and t1.content like '%import%' and t1.content like '%package%' group by 1 ) as t1 group by 1 order by count(t1.package) desc limit 1|"with imports as ( select id, split(regexp_extract(content, r'import\s*\(([^)]*)\)'), '\n') as lines from `bigquery-public-data.github_repos.sample_contents` where regexp_contains(content, r'import\s*\([^)]*\)') ), go_files as ( select id from `bigquery-public-data.github_repos.sample_files` where path like '%.go' group by id ), filtered_imports as ( select id, line from imports, unnest(lines) as line ), joined_data as ( select fi.line from filtered_imports fi join go_files gf on fi.id = gf.id ) select regexp_extract(line, r'""([^""]+)""') as package from joined_data group by package having package is not null order by count(*) desc limit 1;"
bigquery-public-data.github_repos|Identify the top 10 most frequently imported packages and their counts in Java source files.|with javafiles as ( select sample_files.path, sample_contents.content from `bigquery-public-data`.github_repos.sample_files inner join `bigquery-public-data`.github_repos.sample_contents on sample_files.id = sample_contents.id where sample_files.path like '%.java' ) select substring(import_statement, instr(import_statement, ' ') + 1) as imported_package, count(*) as import_count from ( select regexp_extract_all(content, r'import\s+([\w\.-]+)') as import_statement from javafiles ) as imports group by imported_package order by import_count desc limit 10;|select package, count(*) count from ( select regexp_extract(line, r' ([a-z0-9\._]*)\.') as package, id from ( select split(content, '\n') as lines, id from `bigquery-public-data.github_repos.sample_contents` where regexp_contains(content, r'import') and sample_path like '%.java' ), unnest(lines) as line where left(line, 6) = 'import' group by package, id ) group by package order by count desc limit 10;
"bigquery-public-data.github_repos
githubarchive.day"|Which primary programming languages, determined by the highest number of bytes in each repository, have its repositories having at least a total of 100 pull requests on January 18, 2023?|-- unable to provide an sql query without a schema. -- please provide the table schema and column names. -- for example, a possible schema could be: -- -- table: repositories -- - id (int) -- - name (varchar) -- - primary_language (varchar) -- - size_in_bytes (int) -- -- table: pullrequests -- - id (int) -- - repository_id (int) -- - created_at (datetime) -- -- the following query assumes the schema above: -- -- select r.primary_language -- from repositories r -- join pullrequests p on r.id = p.repository_id -- where p.created_at between '2023-01-18 00:00:00' and '2023-01-18 23:59:59' -- group by r.primary_language -- having count(*) >= 100 -- order by r.size_in_bytes desc; please provide the schema of your database so i can provide an accurate sql query.|"-- some reformatting and such of github queries. select language as name, count from ( select * from ( select lang as language, y as year, q as quarter, type, count(*) as count from ( select a.type as type, b.lang as lang, a.y as y, a.q as q from ( select type, extract(year from created_at) as y, extract(quarter from created_at) as q, regexp_replace( repo.url, r'https:\/\/github\.com\/|https:\/\/api\.github\.com\/repos\/', '' ) as name from `githubarchive.day.20230118` -- if needed, you can uncomment and add more tables -- , `githubarchive.day.20140118` ) a join ( select repo_name as name, lang from ( select repo_name, first_value(language) over ( partition by repo_name order by bytes desc ) as lang from ( select repo_name, language.name as language, language.bytes from `bigquery-public-data.github_repos.languages`, unnest(language) as language ) ) where lang is not null group by repo_name, lang ) b on a.name = b.name ) group by type, language, year, quarter order by year, quarter, count desc ) where count >= 100 ) where type = 'pullrequestevent';"
"bigquery-public-data.github_repos
githubarchive.day"|How many pull requests in total were created in repositories that include JavaScript as one of their languages, considering data from January 18, 2023?|-- this query cannot be executed without a defined schema. -- please provide the schema to get the exact sql query. -- the following query assumes a schema with tables 'pull_requests' and 'repositories' -- and appropriate columns for joining and filtering. select count(*) as total_pull_requests from pull_requests pr join repositories r on pr.repository_id = r.id where r.languages like '%javascript%' and pr.created_at >= '2023-01-18'; **explanation:** * this query assumes you have tables named `pull_requests` and `repositories` with relevant columns for joining and filtering. * `join` clause connects the `pull_requests` and `repositories` tables based on the shared `repository_id`. * `where` clause filters the data based on two conditions: * `r.languages like '%javascript%'` selects repositories that have javascript listed in their languages. * `pr.created_at >= '2023-01-18'` filters pull requests created on or after january 18, 2023. * `count(*) as total_pull_requests` counts the total number of pull requests meeting the criteria and aliases it as `total_pull_requests`. **note:** this is a general template, and you might need to adjust the column names and table names to match your specific schema.|"select count(*) as total_pull_requests from ( select a.type as type, b.language as lang, a.y as y, a.q as q from ( select type, extract(year from created_at) as y, extract(quarter from created_at) as q, regexp_replace( repo.url, r'https:\/\/github\.com\/|https:\/\/api\.github\.com\/repos\/', '' ) as name from `githubarchive.day.20230118` -- if needed, you can uncomment and add more tables -- , `githubarchive.day.20140118` ) a join ( select repo_name as name, language from ( select repo_name, language from ( select repo_name, language.name as language, language.bytes from `bigquery-public-data.github_repos.languages`, unnest(language) as language ) ) where language = 'javascript' group by repo_name, language ) b on a.name = b.name ) where type = 'pullrequestevent';"
"bigquery-public-data.github_repos
githubarchive.year"|Find the top 5 repositories from 2017, which have more than 300 unique users watching them, that also have a `pom.xml` file containing the text `<artifactId>junit</artifactId>`. List these repositories in descending order of the watches they have.|-- this query is unable to be executed without a schema. -- please provide the table schema with columns relevant to the requested information. -- this query provides a general structure for retrieving the desired information -- and should be adapted to your specific schema. -- assuming tables: repositories, users, watches, files select r.repository_name from repositories r join watches w on r.repository_id = w.repository_id join users u on w.user_id = u.user_id join files f on r.repository_id = f.repository_id where r.year = 2017 and f.file_name = 'pom.xml' and f.content like '%<artifactid>junit</artifactid>%' group by r.repository_name having count(distinct u.user_id) > 300 order by count(distinct u.user_id) desc limit 5; **explanation:** 1. **joins:** - `repositories` table is joined with `watches` table on `repository_id` to get the users watching each repository. - `watches` table is joined with `users` table on `user_id` to get the unique user ids. - `repositories` table is joined with `files` table on `repository_id` to find `pom.xml` files within each repository. 2. **filtering:** - `r.year = 2017`: filters repositories from 2017. - `f.file_name = 'pom.xml'`: filters for repositories containing `pom.xml` files. - `f.content like '%<artifactid>junit</artifactid>%'`: filters repositories with `pom.xml` files containing the specific text. 3. **grouping and filtering:** - `group by r.repository_name`: groups results by repository name. - `having count(distinct u.user_id) > 300`: filters groups where the number of unique users watching the repository is greater than 300. 4. **sorting:** - `order by count(distinct u.user_id) desc`: sorts the results in descending order based on the number of unique users watching each repository. 5. **limit:** - `limit 5`: returns only the top 5 repositories. **remember to adapt this query to your specific schema.** replace table and column names with the actual names from your database.|with repos as ( select b.repo_with_watches as repo_name, b.watches as watches from ( select distinct repo_name as repo_in_mirror from `bigquery-public-data.github_repos.sample_files` ) a right join ( select repo.name as repo_with_watches, approx_count_distinct(actor.id) watches from `githubarchive.year.2017` where type='watchevent' group by 1 having watches > 300 ) b on a.repo_in_mirror = b.repo_with_watches where a.repo_in_mirror is not null ), contents as ( select * from ( select distinct * from `bigquery-public-data.github_repos.sample_files` where repo_name in (select repo_name from repos) ) a right join ( select id as idcontent, content as content from `bigquery-public-data.github_repos.sample_contents` ) b on a.id = b.idcontent ) select repos.repo_name, repos.watches from repos join contents on repos.repo_name = contents.repo_name where contents.content like '%junit</artifactid>%' and contents.path like 'pom.xml' order by repos.watches desc limit 5
"bigquery-public-data.github_repos
githubarchive.month"|Which repository with an approved license in `licenses.md` had the highest combined total of forks, issues, and watches in April 2022?|-- this query cannot be executed without a schema. -- this is a conceptual query to illustrate the logic. -- replace the placeholders with actual table and column names from your schema. select repository_name from repositories where -- replace with the actual condition to check for an approved license in `licenses.md` license_status = 'approved' and date between '2022-04-01' and '2022-04-30' order by forks + issues + watches desc limit 1; **explanation:** 1. **`select repository_name`:** this line specifies that we want to retrieve the name of the repository. 2. **`from repositories`:** this specifies the table containing the repository data. 3. **`where` clause:** * **`license_status = 'approved'`:** this condition filters the repositories to only include those with an approved license. you'll need to replace this condition with the actual logic to check for the approved license based on your schema and the `licenses.md` file. * **`date between '2022-04-01' and '2022-04-30'`:** this condition filters the repositories to only include those with data from april 2022. you might need to adjust the date range based on the actual date format in your schema. 4. **`order by forks + issues + watches desc`:** this sorts the results in descending order based on the sum of forks, issues, and watches. 5. **`limit 1`:** this limits the result to only the top repository with the highest combined total. **important:** this query assumes the existence of columns like `repository_name`, `license_status`, `forks`, `issues`, and `watches` in your `repositories` table. you need to adapt the query to match your actual schema and table names.|"with allowed_repos as ( select repo_name, license from `bigquery-public-data.github_repos.licenses` where license in unnest( [""gpl-3.0"", ""artistic-2.0"", ""isc"", ""cc0-1.0"", ""epl-1.0"", ""gpl-2.0"", ""mpl-2.0"", ""lgpl-2.1"", ""bsd-2-clause"", ""apache-2.0"", ""mit"", ""lgpl-3.0""]) ), watch_counts as ( select repo.name as repo, count(distinct actor.login) watches, from `githubarchive.month.202204` where type = ""watchevent"" group by repo ), issue_counts as ( select repo.name as repo, count(*) issue_events, from `githubarchive.month.202204` where type = 'issuesevent' group by repo ), fork_counts as ( select repo.name as repo, count(*) forks, from `githubarchive.month.202204` where type = 'forkevent' group by repo ) select repo_name from allowed_repos inner join fork_counts on repo_name = fork_counts.repo inner join issue_counts on repo_name = issue_counts.repo inner join watch_counts on repo_name = watch_counts.repo order by forks + issue_events + watches desc limit 1;"
bigquery-public-data.github_repos|"Which repository that has a license of either ""artistic-2.0"", ""isc"", ""mit"", or ""apache-2.0"", contains Python files in the master branch, and has the highest combined count of forks, issues, and watch events in April 2022?"|with repositorystats as ( select repo_name, count(distinct forks.forkee_owner) as fork_count, count(distinct issues.issue_number) as issue_count, count(distinct watch_events.actor) as watch_count from `bigquery-public-data`.github_repos.sample_repos as repos left join `bigquery-public-data`.githubarchive.month as forks on repos.repo_name = forks.repo.name and forks.type = 'forkevent' and cast(forks.created_at as string) like '2022-04%' left join `bigquery-public-data`.githubarchive.month as issues on repos.repo_name = issues.repo.name and issues.type = 'issuesevent' and cast(issues.created_at as string) like '2022-04%' left join `bigquery-public-data`.githubarchive.month as watch_events on repos.repo_name = watch_events.repo.name and watch_events.type = 'watchevent' and cast(watch_events.created_at as string) like '2022-04%' group by 1 ), pythonrepos as ( select repo_name from `bigquery-public-data`.github_repos.sample_files where ref = 'master' and path like '%.py' ) select rs.repo_name from repositorystats as rs join pythonrepos as pr on rs.repo_name = pr.repo_name join `bigquery-public-data`.github_repos.licenses as lic on rs.repo_name = lic.repo_name where lic.license in ('artistic-2.0', 'isc', 'mit', 'apache-2.0') order by rs.fork_count + rs.issue_count + rs.watch_count desc limit 1;|"with allowed_repos as ( select repo_name, license from `bigquery-public-data.github_repos.licenses` where license in unnest([""artistic-2.0"", ""isc"", ""mit"", ""apache-2.0""]) ), watch_counts as ( select repo.name as repo, count(distinct actor.login) as watches from `githubarchive.month.202204` where type = ""watchevent"" group by repo ), issue_counts as ( select repo.name as repo, count(*) as issue_events from `githubarchive.month.202204` where type = 'issuesevent' group by repo ), fork_counts as ( select repo.name as repo, count(*) as forks from `githubarchive.month.202204` where type = 'forkevent' group by repo ), metadata as ( select repo_name, license, forks, issue_events, watches from allowed_repos inner join fork_counts on repo_name = fork_counts.repo inner join issue_counts on repo_name = issue_counts.repo inner join watch_counts on repo_name = watch_counts.repo ), github_files_at_head as ( select repo_name from `bigquery-public-data.github_repos.sample_files` where ref = ""refs/heads/master"" and ends_with(path, "".py"") and symlink_target is null group by repo_name ) select metadata.repo_name as repository from metadata inner join github_files_at_head on metadata.repo_name = github_files_at_head.repo_name order by (metadata.forks + metadata.issue_events + metadata.watches) desc limit 1;"
bigquery-public-data.github_repos|What's the top 3 widely used languages according to file counts?|with languagecounts as ( select t1.name as language, sum(t2.bytes) as total_bytes from `bigquery-public-data`.github_repos.languages as t1, unnest(t1.language) as t2 group by 1 ) select language, total_bytes from languagecounts order by total_bytes desc limit 3|with languages as ( select files.id, case regexp_extract(files.path, r'(\.?[^\/\.]*)$') when '.js' then 'javascript' when '.cjs' then 'javascript' when '.ts' then 'typescript' when '.java' then 'java' when '.py' then 'python' when '.kt' then 'kotlin' when '.ktm' then 'kotlin' when '.kts' then 'kotlin' when '.c' then 'c' when '.h' then 'c' when '.c++' then 'c++' when '.cpp' then 'c++' when '.h++' then 'c++' when '.hpp' then 'c++' when '.cs' then 'c#' when '.erl' then 'erlang' when '.ex' then 'elixir' when '.exs' then 'elixir' when '.hs' then 'haskell' when '.go' then 'go' when '.php' then 'php' when '.rb' then 'ruby' when '.rs' then 'rust' when '.scala' then 'scala' when '.swift' then 'swift' when '.lisp' then 'common lisp' when '.clj' then 'clojure' when '.r' then 'r' when '.matlab' then 'matlab' when '.m' then 'matlab' when '.asm' then 'assembly' when '.nasm' then 'assembly' when '.d' then 'd' when '.dart' then 'dart' when '.jl' then 'julia' when '.groovy' then 'groovy' when '.hx' then 'haxe' when '.lua' then 'lua' when '.sh' then 'shell' when '.bash' then 'shell' when '.ps1' then 'powershell' when '.psd1' then 'powershell' when '.psm1' then 'powershell' when '.sql' then 'sql' when 'dockerfile' then 'dockerfile' when '.dockerfile' then 'dockerfile' when '.md' then 'markdown' when '.markdown' then 'markdown' when '.mdown' then 'markdown' when '.html' then 'html' when '.htm' then 'html' when '.css' then 'css' when '.sass' then 'sass' when '.scss' then 'scss' when '.vue' then 'vue' when '.json' then 'json' when '.yml' then 'yaml' when '.yaml' then 'yaml' when '.xml' then 'xml' end as language from `bigquery-public-data.github_repos.sample_files` as files ) select languages.language from languages inner join `bigquery-public-data.github_repos.sample_contents` as contents on contents.id = languages.id where languages.language is not null and contents.content is not null group by languages.language order by count(*) desc limit 3;
bigquery-public-data.github_repos|Please help me retrieve the top 3 most frequently used module names from Python and R scripts.|"with pythonmodules as ( select t2.sample_path, t2.content, regexp_extract_all(t2.content, r'""[a-za-z0-9_]+""') as modules from `bigquery-public-data`.github_repos.sample_files as t1 inner join `bigquery-public-data`.github_repos.sample_contents as t2 on t1.id = t2.id where t1.path like '%.py' ), rmodules as ( select t2.sample_path, t2.content, regexp_extract_all(t2.content, r'""[a-za-z0-9_]+""') as modules from `bigquery-public-data`.github_repos.sample_files as t1 inner join `bigquery-public-data`.github_repos.sample_contents as t2 on t1.id = t2.id where t1.path like '%.r' ), combinedmodules as ( select sample_path, modules from pythonmodules union all select sample_path, modules from rmodules ) select modules, count(*) as frequency from combinedmodules, unnest(modules) as modules group by modules order by frequency desc limit 3;"|"select module, count(*) as occurrence_count from ( select file_id, repo_name, path, line, array_concat( if( ends_with(path, '.py'), array_concat( regexp_extract_all(line, r'\bimport\s+(\w+)'), regexp_extract_all(line, r'\bfrom\s+(\w+)') ), [] ), if( ends_with(path, '.r'), regexp_extract_all(line, r'library\s*\(\s*([^\s)]+)\s*\)'), [] ) ) as modules from ( select ct.id as file_id, fl.repo_name, path, split(replace(ct.content, ""\n"", "" \n""), ""\n"") as lines from `bigquery-public-data.github_repos.sample_files` as fl join `bigquery-public-data.github_repos.sample_contents` as ct on fl.id = ct.id ), unnest(lines) as line where (ends_with(path, '.py') and (regexp_contains(line, r'^import ') or regexp_contains(line, r'^from '))) or (ends_with(path, '.r') and regexp_contains(line, r'library\s*\(')) ), unnest(modules) as module group by module order by occurrence_count desc limit 3"
bigquery-public-data.github_repos|Can you find the top 5 most frequently imported Python modules and R libraries from the GitHub sample files and list them along with their occurrence counts? Please sort the results by language and then by the number of occurrences in descending order.|"with imports as ( select case when sample_path like '%.py' then 'python' when sample_path like '%.r' then 'r' else null end as language, regexp_extract(content, r'from\s+([^\s]+)\s+import\s+|\simport\s+([^\s]+)') as module, count(*) as occurrences from `bigquery-public-data`.github_repos.sample_contents where language is not null group by 1, 2 ) select language, module, occurrences from imports where not module is null group by 1, 2, 3 order by language, occurrences desc limit 5;"|"with extracted_modules as ( select file_id, repo_name, path, line, if( ends_with(path, '.py'), 'python', if(ends_with(path, '.r'), 'r', null) ) as language, if( ends_with(path, '.py'), array_concat( regexp_extract_all(line, r'\bimport\s+(\w+)'), regexp_extract_all(line, r'\bfrom\s+(\w+)') ), if( ends_with(path, '.r'), regexp_extract_all(line, r'library\s*\(\s*([^\s)]+)\s*\)'), [] ) ) as modules from ( select ct.id as file_id, fl.repo_name, path, split(replace(ct.content, ""\n"", "" \n""), ""\n"") as lines from `bigquery-public-data.github_repos.sample_files` as fl join `bigquery-public-data.github_repos.sample_contents` as ct on fl.id = ct.id ), unnest(lines) as line where (ends_with(path, '.py') and (regexp_contains(line, r'^import ') or regexp_contains(line, r'^from '))) or (ends_with(path, '.r') and regexp_contains(line, r'library\s*\(')) ), module_counts as ( select language, module, count(*) as occurrence_count from ( select language, modules from extracted_modules where modules is not null ),unnest(modules) as module group by language, module ), top5_python as ( select 'python' as language, module, occurrence_count from module_counts where language = 'python' order by occurrence_count desc limit 5 ), top5_r as ( select 'r' as language, module, occurrence_count from module_counts where language = 'r' order by occurrence_count desc limit 5 ) select * from top5_python union all select * from top5_r order by language, occurrence_count desc;"
bigquery-public-data.github_repos|Among all 'requirements.txt' files in repositories containing Python code, how much percentage of them include the 'requests' package?|with pythonrepos as ( select distinct repo_name from bigquery-public-data.github_repos.languages where array_to_string(array(select t.name from unnest(language) as t), ', ') like '%python%' ), requirementsfiles as ( select distinct f.repo_name from bigquery-public-data.github_repos.sample_files as f inner join pythonrepos as pr on f.repo_name = pr.repo_name where f.path = 'requirements.txt' ), requestsfiles as ( select distinct f.repo_name from bigquery-public-data.github_repos.sample_contents as c inner join requirementsfiles as f on c.sample_repo_name = f.repo_name where c.content like '%requests%' ) select cast(count(distinct rf.repo_name) as float64) * 100 / count(distinct rf2.repo_name) as percentage from requestsfiles as rf inner join requirementsfiles as rf2 on rf.repo_name = rf2.repo_name;|with requests as ( select d.id, d.content, e.repo_name, e.path from ( select id, content from `bigquery-public-data.github_repos.sample_contents` group by id, content ) as d inner join ( select c.id, c.repo_name, c.path from ( select id, repo_name, path from `bigquery-public-data.github_repos.sample_files` where lower(path) like '%requirements.txt' group by path, id, repo_name ) as c inner join ( select repo_name, language_struct.name as language_name from `bigquery-public-data.github_repos.languages`, unnest(language) as language_struct where lower(language_struct.name) like '%python%' group by language_name, repo_name ) as f on c.repo_name = f.repo_name ) as e on d.id = e.id ) select (select count(*) from requests where content like '%requests%') / count(*) as proportion from requests
bigquery-public-data.github_repos|Among the repositories from the GitHub Archive which include a Python file with less than 15,000 bytes in size and a keyword 'def' in the content, find the top 3 that have the highest number of watch events in 2017?|with pythonfiles as ( select sf.repo_name from `bigquery-public-data`.github_repos.sample_files as sf inner join `bigquery-public-data`.github_repos.sample_contents as sc on sf.id = sc.id where sf.path like '%.py' and sc.size < 15000 and sc.content like '%def%' ), watchcounts as ( select repo_name, count(*) as watch_count from `bigquery-public-data`.githubarchive.month where type = 'watchevent' and cast(strftime('%y', created_at) as int64) = 2017 group by repo_name ) select wc.repo_name, wc.watch_count from watchcounts as wc inner join pythonfiles as pf on wc.repo_name = pf.repo_name order by wc.watch_count desc limit 3;|"with watched_repos as ( select repo.name as repo from `githubarchive.month.2017*` where type = ""watchevent"" ), repo_watch_counts as ( select repo, count(*) as watch_count from watched_repos group by repo ) select r.repo, r.watch_count from `bigquery-public-data.github_repos.sample_files` as f join `bigquery-public-data.github_repos.sample_contents` as c on f.id = c.id join repo_watch_counts as r on f.repo_name = r.repo where f.path like '%.py' and c.size < 15000 and regexp_contains(c.content, r'def ') group by r.repo, r.watch_count order by r.watch_count desc limit 3;"
bigquery-public-data.github_repos|Can you provide a report showing the counts of different types of lines in SQL files from the GitHub repository in descending order, specifically categorizing them into 'trailing' if there is at least one blank character at the end of the line, 'Space' if the line starts with at least one space, and 'Other' for any other types? |select case when length(trim(trailing ' ' from content)) < length(content) then 'trailing' when substr(content, 1, 1) = ' ' then 'space' else 'other' end as line_type, count(*) as count from `bigquery-public-data`.github_repos.sample_contents where sample_repo_name = 'torvalds/linux' and sample_path like '%.sql' and not content like '%--%' -- exclude comments group by line_type order by count desc; **explanation:** 1. **`select ... case ... end as line_type, count(*) as count`**: this part defines the columns in the report: - `line_type`: categorizes each line based on the following conditions: - `trailing`: if the length of the line after removing trailing spaces is less than the original length, it indicates trailing spaces. - `space`: if the first character of the line is a space. - `other`: for any other cases. - `count`: counts the occurrences of each line type. 2. **`from ...`**: specifies the table `bigquery-public-data.github_repos.sample_contents` as the source of data. 3. **`where ...`**: filters the data based on the following conditions: - `sample_repo_name = 'torvalds/linux'`: limits the analysis to the specific repository. - `sample_path like '%.sql'`: selects only files with the `.sql` extension. - `not content like '%--%'`: excludes lines containing comments (`--`). 4. **`group by line_type`**: groups the data by `line_type` to count occurrences for each category. 5. **`order by count desc`**: sorts the results in descending order based on the `count` column to show the most common line types first.|"with lines as ( select split(content, '\\n') as line, id from `bigquery-public-data.github_repos.sample_contents` where sample_path like ""%.sql"" ) select indentation, count(indentation) as number_of_occurence from ( select case when min(char_length(regexp_extract(flatten_line, r""\s+$"")))>=1 then 'trailing' when min(char_length(regexp_extract(flatten_line, r""^ +"")))>=1 then 'space' else 'other' end as indentation from lines cross join unnest(lines.line) as flatten_line group by id) group by indentation order by number_of_occurence desc"
